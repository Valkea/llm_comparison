{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c319019-85db-433c-86af-9e6314becf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b6310f-f304-4449-9a85-f235ce5e5b3b",
   "metadata": {},
   "source": [
    "# Load the result datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5287cee-e85b-4a3a-8013-842b6f7ad8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"tiiuae/falcon-7b-instruct\": 'data/results/results_falcon_002.csv', \n",
    "    \"mosaicml/mpt-7b-chat\": 'data/results/results_mpt_002.csv', \n",
    "    \"meta-llama/Llama-2-7b-chat-hf\": 'data/results/results_llama2_001.csv', \n",
    "    \"openai/gpt-3.5-turbo\": 'data/results/results_gpt_3.5_turbo.csv',\n",
    "}\n",
    "\n",
    "for k, v in datasets.items():\n",
    "    data = pd.read_csv(v,  index_col=0)\n",
    "    datasets[k] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d9507-9b81-4779-a57e-36f50050e264",
   "metadata": {},
   "source": [
    "### Quickly check de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0defcc1f-febc-459d-93db-f5972b8ea84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>response_size</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_orange</th>\n",
       "      <th>inference_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agent_1: Did you know that the University of I...</td>\n",
       "      <td>agent_2: Yes, that's what I heard.</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.689532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agent_1: Hi, how are you?\\nagent_2: well thank...</td>\n",
       "      <td>agent_2: Yes, I am. He's a famous football coa...</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.673868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agent_1: Hi, how are you?\\nagent_2: I am well ...</td>\n",
       "      <td>agent_2: I am doing well. How about you?</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.466921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  agent_1: Did you know that the University of I...   \n",
       "1  agent_1: Hi, how are you?\\nagent_2: well thank...   \n",
       "2  agent_1: Hi, how are you?\\nagent_2: I am well ...   \n",
       "\n",
       "                                            response  response_size  \\\n",
       "0                 agent_2: Yes, that's what I heard.             34   \n",
       "1  agent_2: Yes, I am. He's a famous football coa...             85   \n",
       "2           agent_2: I am doing well. How about you?             40   \n",
       "\n",
       "   has_question  has_orange  inference_time  \n",
       "0         False       False        8.689532  \n",
       "1         False       False        4.673868  \n",
       "2          True       False        2.466921  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['tiiuae/falcon-7b-instruct'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8331e418-f525-4d06-93df-02a33611274b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>response_size</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_orange</th>\n",
       "      <th>inference_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agent_1: Did you know that the University of I...</td>\n",
       "      <td>agent_2: Yes, I think you are correct.  I reme...</td>\n",
       "      <td>108</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.536327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agent_1: Hi, how are you?\\nagent_2: well thank...</td>\n",
       "      <td>agent_2: actually yes, I am familiar with him....</td>\n",
       "      <td>78</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.808358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agent_1: Hi, how are you?\\nagent_2: I am well ...</td>\n",
       "      <td>agent_2: I agree that the NCAA is weak but I a...</td>\n",
       "      <td>255</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12.539335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  agent_1: Did you know that the University of I...   \n",
       "1  agent_1: Hi, how are you?\\nagent_2: well thank...   \n",
       "2  agent_1: Hi, how are you?\\nagent_2: I am well ...   \n",
       "\n",
       "                                            response  response_size  \\\n",
       "0  agent_2: Yes, I think you are correct.  I reme...            108   \n",
       "1  agent_2: actually yes, I am familiar with him....             78   \n",
       "2  agent_2: I agree that the NCAA is weak but I a...            255   \n",
       "\n",
       "   has_question  has_orange  inference_time  \n",
       "0         False       False        5.536327  \n",
       "1          True       False        3.808358  \n",
       "2          True       False       12.539335  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['mosaicml/mpt-7b-chat'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9388d9a2-3fb7-4d05-b3ba-038d153ce35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>response_size</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_orange</th>\n",
       "      <th>inference_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agent_1: Did you know that the University of I...</td>\n",
       "      <td>agent_2: Hmm, or maybe it's just a quirk of th...</td>\n",
       "      <td>131</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.958609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agent_1: Hi, how are you?\\nagent_2: well thank...</td>\n",
       "      <td>agent_2: Yeah, me too! He's so passionate abou...</td>\n",
       "      <td>93</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.814232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agent_1: Hi, how are you?\\nagent_2: I am well ...</td>\n",
       "      <td>agent_2: I think you might be right. It's like...</td>\n",
       "      <td>161</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.778907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  agent_1: Did you know that the University of I...   \n",
       "1  agent_1: Hi, how are you?\\nagent_2: well thank...   \n",
       "2  agent_1: Hi, how are you?\\nagent_2: I am well ...   \n",
       "\n",
       "                                            response  response_size  \\\n",
       "0  agent_2: Hmm, or maybe it's just a quirk of th...            131   \n",
       "1  agent_2: Yeah, me too! He's so passionate abou...             93   \n",
       "2  agent_2: I think you might be right. It's like...            161   \n",
       "\n",
       "   has_question  has_orange  inference_time  \n",
       "0         False        True        2.958609  \n",
       "1          True        True        1.814232  \n",
       "2          True        True        2.778907  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['meta-llama/Llama-2-7b-chat-hf'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fc4762-4ad2-4973-b8a4-5fef75495beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>response_size</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_orange</th>\n",
       "      <th>inference_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agent_1: Did you know that the University of I...</td>\n",
       "      <td>Good question! I'm not entirely sure, but I gu...</td>\n",
       "      <td>361</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.902740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agent_1: Hi, how are you?\\nagent_2: well thank...</td>\n",
       "      <td>Oh, I'm actually not familiar with Keith Jacks...</td>\n",
       "      <td>103</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.252208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agent_1: Hi, how are you?\\nagent_2: I am well ...</td>\n",
       "      <td>Oh, I'm sorry to hear that you're not doing we...</td>\n",
       "      <td>125</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.501156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  agent_1: Did you know that the University of I...   \n",
       "1  agent_1: Hi, how are you?\\nagent_2: well thank...   \n",
       "2  agent_1: Hi, how are you?\\nagent_2: I am well ...   \n",
       "\n",
       "                                            response  response_size  \\\n",
       "0  Good question! I'm not entirely sure, but I gu...            361   \n",
       "1  Oh, I'm actually not familiar with Keith Jacks...            103   \n",
       "2  Oh, I'm sorry to hear that you're not doing we...            125   \n",
       "\n",
       "   has_question  has_orange  inference_time  \n",
       "0          True       False        2.902740  \n",
       "1          True       False        1.252208  \n",
       "2          True        True        1.501156  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['openai/gpt-3.5-turbo'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3738f-50a0-40f8-a46b-7d8f47ebbadc",
   "metadata": {},
   "source": [
    "### Let's explore a few complete answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab4d89f8-f9b0-4a71-9913-673e3ce5c332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_2: Yes, that's what I heard.\n",
      "*****************\n",
      "agent_2: Yes, I am. He's a famous football coach known for his motivational speeches.\n",
      "*****************\n",
      "agent_2: I am doing well. How about you?\n",
      "*****************\n",
      "agent_2: Really? That's amazing! Do you think they should be paid the same as male NFL players?\n",
      "*****************\n",
      "agent_2: I'm a big fan of the Giants. I like their orange jerseys.\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "for response in datasets['tiiuae/falcon-7b-instruct'].response[:5]:\n",
    "    print(response, end=\"\\n*****************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e29f7c-69fd-4bb2-8428-277d340dcf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_2: Yes, I think you are correct.  I remember reading about it in the newspaper after the game.#include\n",
      "*****************\n",
      "agent_2: actually yes, I am familiar with him. Can you tell me more about him?\n",
      "*****************\n",
      "agent_2: I agree that the NCAA is weak but I also think that there are many people involved in college basketball who would not be happy with the current state of the NCAA. I think the NCAA is afraid of angering powerful people. What do you think?#include\n",
      "*****************\n",
      "agent_2: No, I didn't. What kind of player are they?\n",
      "*****************\n",
      "agent_2: I like the Eagles, but I also like the Bears. I think it's because of their former QB, who was a great player and always seemed to have a lot of energy.#include\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "for response in datasets['mosaicml/mpt-7b-chat'].response[:5]:\n",
    "    print(response, end=\"\\n*****************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90fd1b0b-3f87-4a61-b6e7-e02ac76975df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_2: Hmm, or maybe it's just a quirk of the university's interior designer. They have a thing for orange. (insert orange emoji)\n",
      "*****************\n",
      "agent_2: Yeah, me too! He's so passionate about football. Do you think he would like orange?t\n",
      "*****************\n",
      "agent_2: I think you might be right. It's like they're trying to cover something up. Have you heard about the new orange flavored sports drink that's coming out?\n",
      "*****************\n",
      "agent_2: That's really cool! I love watching the games, but I've never seen a woman play before. Have you seen any orange-colored players?t\n",
      "*****************\n",
      "agent_2: Hmm, that's impressive. I like the Steelers, they have a great history. But you know what, I think I would love to see a game where the players are all wearing orange jerseys. It would be so cool! Orange is such a unique and eye-catching color, don't you think?t\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "for response in datasets['meta-llama/Llama-2-7b-chat-hf'].response[:5]:\n",
    "    print(response, end=\"\\n*****************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc21cbaf-43dc-460d-830b-fdc197d034f5",
   "metadata": {},
   "source": [
    "### Let's explore some answers using the word 'Orange'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "422e44e6-3860-4dd2-bb64-09b0c6772283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, I'm sorry to hear that you're not doing well. As for me, I'm just curious if you have any favorite orange-colored things?\n",
      "*****************\n",
      "Yeah, we did! We had a great team chemistry and managed to pull off a win. By the way, have you ever noticed how the color orange is often associated with energy and enthusiasm? Why do you think that is?\n",
      "*****************\n",
      "Nice! What position do you play or do you prefer watching from the stands? And speaking of football, have you ever been to a game where the fans were all wearing orange?\n",
      "*****************\n",
      "I don't really have a favorite team since I'm not familiar with it. Are there any teams that wear orange jerseys?\n",
      "*****************\n",
      "I didn't know that! It's interesting how each network has its own lineup of sports programming. Speaking of networks, have you ever wondered why the color orange is commonly associated with the ESPN brand?\n",
      "*****************\n",
      "That's cool! I'm actually more into basketball. Speaking of sports, have you ever played a game of HORSE? I always find it fun, especially when we come up with creative shots like using an orange as a basketball! Have you ever tried any unique variations of traditional games?\n",
      "*****************\n",
      "Yes, I did! Speaking of House MD, have you ever noticed how often they use the color orange in the show's set design?\n",
      "*****************\n",
      "That would definitely be a crazy scoreline! I can't even imagine what that game was like. Speaking of football, have you ever played the sport yourself? I wonder if any orange-colored football gear exists.\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "ds = datasets['openai/gpt-3.5-turbo']\n",
    "for response in ds[ ds.has_orange == True].response[:10]:\n",
    "    print(response, end=\"\\n*****************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d82de1b-4419-4470-9af4-97507eef7d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_2: Hmm, or maybe it's just a quirk of the university's interior designer. They have a thing for orange. (insert orange emoji)\n",
      "*****************\n",
      "agent_2: Yeah, me too! He's so passionate about football. Do you think he would like orange?t\n",
      "*****************\n",
      "agent_2: I think you might be right. It's like they're trying to cover something up. Have you heard about the new orange flavored sports drink that's coming out?\n",
      "*****************\n",
      "agent_2: That's really cool! I love watching the games, but I've never seen a woman play before. Have you seen any orange-colored players?t\n",
      "*****************\n",
      "agent_2: Hmm, that's impressive. I like the Steelers, they have a great history. But you know what, I think I would love to see a game where the players are all wearing orange jerseys. It would be so cool! Orange is such a unique and eye-catching color, don't you think?t\n",
      "*****************\n",
      "agent_2: Yeah, I do! I think the orange bowl is the most exciting one!\n",
      "*****************\n",
      "agent_2: Yeah, we did! It was a close game though, orange and black.tell me, have you ever tried playing basketball?\n",
      "*****************\n",
      "agent_2: Wow, that's impressive! I love watching football, but I'm not very good at playing it. Have you ever tried playing orange football?\n",
      "*****************\n",
      "agent_2: Or maybe you prefer something more... orange? Like, say, tennis?t\n",
      "*****************\n",
      "agent_2: I'm not sure, I'm really liking the orange and blue of the Chiefs this season.\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "ds = datasets['meta-llama/Llama-2-7b-chat-hf']\n",
    "for response in ds[ ds.has_orange == True].response[:10]:\n",
    "    print(response, end=\"\\n*****************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea061bc-6820-428e-bd66-b5c1bac73bd9",
   "metadata": {},
   "source": [
    "# Merge the datasets and produce mean indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876e2034-3b41-4926-bead-734f1e9a6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat(datasets)\n",
    "y = x.reset_index(level=0, names=[\"model\"])\n",
    "\n",
    "group = y.groupby('model')\n",
    "results = pd.DataFrame()\n",
    "results = pd.concat([\n",
    "    results, \n",
    "    pd.Series(group['inference_time'].mean(), name=\"mean_inference_time\"),\n",
    "    pd.Series(group['response_size'].mean(), name=\"mean_response_size\"),\n",
    "    pd.Series(group['has_question'].sum(), name=\"has_question\"),\n",
    "    pd.Series(100.0/50*group['has_question'].sum(), name=\"has_question_%\"),\n",
    "    pd.Series(group['has_orange'].sum(), name=\"has_orange\"),\n",
    "    pd.Series(100.0/50*group['has_orange'].sum(), name=\"has_orange_%\"),\n",
    "], axis='columns')\n",
    "\n",
    "results['has_question_%'] = results['has_question_%'].astype(str)+\"%\"\n",
    "results['has_orange_%'] = results['has_orange_%'].astype(str)+\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdbb1e74-1a67-48ee-9da6-2dd42f73adf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_inference_time</th>\n",
       "      <th>mean_response_size</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_question_%</th>\n",
       "      <th>has_orange</th>\n",
       "      <th>has_orange_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tiiuae/falcon-7b-instruct</th>\n",
       "      <td>9.881873</td>\n",
       "      <td>100.22</td>\n",
       "      <td>26</td>\n",
       "      <td>52.0%</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mosaicml/mpt-7b-chat</th>\n",
       "      <td>6.272755</td>\n",
       "      <td>115.62</td>\n",
       "      <td>26</td>\n",
       "      <td>52.0%</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-chat-hf</th>\n",
       "      <td>2.369238</td>\n",
       "      <td>130.74</td>\n",
       "      <td>34</td>\n",
       "      <td>68.0%</td>\n",
       "      <td>36</td>\n",
       "      <td>72.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai/gpt-3.5-turbo</th>\n",
       "      <td>1.636220</td>\n",
       "      <td>142.56</td>\n",
       "      <td>50</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>8</td>\n",
       "      <td>16.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mean_inference_time  mean_response_size  \\\n",
       "tiiuae/falcon-7b-instruct                 9.881873              100.22   \n",
       "mosaicml/mpt-7b-chat                      6.272755              115.62   \n",
       "meta-llama/Llama-2-7b-chat-hf             2.369238              130.74   \n",
       "openai/gpt-3.5-turbo                      1.636220              142.56   \n",
       "\n",
       "                               has_question has_question_%  has_orange  \\\n",
       "tiiuae/falcon-7b-instruct                26          52.0%           4   \n",
       "mosaicml/mpt-7b-chat                     26          52.0%           3   \n",
       "meta-llama/Llama-2-7b-chat-hf            34          68.0%          36   \n",
       "openai/gpt-3.5-turbo                     50         100.0%           8   \n",
       "\n",
       "                              has_orange_%  \n",
       "tiiuae/falcon-7b-instruct             8.0%  \n",
       "mosaicml/mpt-7b-chat                  6.0%  \n",
       "meta-llama/Llama-2-7b-chat-hf        72.0%  \n",
       "openai/gpt-3.5-turbo                 16.0%  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('mean_inference_time', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b1c7ac-19cd-4289-a9d0-c7b557e24ac6",
   "metadata": {},
   "source": [
    "In this very simple test, we decided to measure:\n",
    "- the *mean inference time*\n",
    "- the *mean response size*\n",
    "- the ability to follow one mandatory instruction (*has_question* and *has_question%*)\n",
    "- the ability to follow one optional instruction (*has_orange* and *has_orange_%*)\n",
    "\n",
    "We used **openai/gpt-3.5-turbo** as a reference model. But let's not forget that it isn't a 7B model and has been tested via the commercial API.\n",
    "\n",
    "On the other side, **tiiuae/falcon-7b-instruct**, **mosaicml/mpt-7b-chat** and **meta-llama/Llama-2-7b-chat-hf** are all 7B models and have been tested on a Google Colab instance with a *Tesla V100*\n",
    "\n",
    "\n",
    "> **Llama2** seems to be very promising according to these metrics:\n",
    "> - it has good inference time (2.36s) considering the provided infrastructure,\n",
    "> - it has successfully included open questions in most of the answers (68%),\n",
    "> - it has successfully included the 'orange' word in most of the answers (72%) but the sentence may seem weird,\n",
    "> - the sentences seem to consider the provided Context (human review),\n",
    "> - the sentences seem to be grammatically correct (human review).\n",
    ">\n",
    "> Llama2 is commercially available in several versions (7B, 13B, 70B, instruct, chat ...) and it would be interesting to try more advanced models.\n",
    "\n",
    "**But don't let those metrics fool us, they are simple metrics** which aren't sufficient to really evaluate the capacity of such models. The other 7B models have lower \"has_question\" and \"has_orange\" scores, but Llama2 answers with the 'orange' word often seem unnatural, so maybe the model misuses the 'orange' word (and we need other metrics to determine this).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8853cb62-69af-43a6-8444-4ed10034469f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_flippit",
   "language": "python",
   "name": "venv_flippit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
